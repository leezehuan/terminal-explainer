#!/usr/bin/env python3

import sys
import os
import requests
import json
import configparser  # ç”¨äºè§£æ .ini é…ç½®æ–‡ä»¶
from pathlib import Path # ç”¨äºä¼˜é›…åœ°å¤„ç†æ–‡ä»¶è·¯å¾„

def load_config():
    """
    åŠ è½½é…ç½®ä¿¡æ¯ã€‚
    é…ç½®çš„å”¯ä¸€æ¥æºæ˜¯ ~/.config/terminal-explainer/config.ini æ–‡ä»¶ã€‚
    
    è¿”å›:
        ä¸€ä¸ªåŒ…å«é…ç½®ä¿¡æ¯çš„å­—å…¸ (dict)ã€‚
    """
    # 1. è®¾ç½®é»˜è®¤é…ç½®
    config = {
        'api_key': None,
        'api_url': 'https://api.openai.com/v1/chat/completions',
        'model': 'gpt-3.5-turbo'
    }

    # 2. ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–é…ç½®ï¼Œå¹¶è¦†ç›–é»˜è®¤å€¼
    config_path = Path.home() / '.config' / 'terminal-explainer' / 'config.ini'
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not config_path.exists():
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›é”™è¯¯ï¼Œå› ä¸ºè¿™æ˜¯å”¯ä¸€çš„é…ç½®æ–¹å¼
        return None, f"\n\033[31mé”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼\nè¯·ç¡®ä¿ ~/.config/terminal-explainer/config.ini æ–‡ä»¶å­˜åœ¨å¹¶å·²æ­£ç¡®é…ç½®ã€‚\033[0m"

    parser = configparser.ConfigParser()
    parser.read(config_path, encoding='utf-8')
    
    if 'API' in parser:
        api_config = parser['API']
        config['api_key'] = api_config.get('api_key', config['api_key'])
        config['api_url'] = api_config.get('api_url', config['api_url'])
        config['model'] = api_config.get('model', config['model'])
    
    # 3. æ¸…ç†å¯èƒ½å­˜åœ¨çš„å ä½ç¬¦
    if config['api_key'] == 'YOUR_API_KEY_HERE':
        config['api_key'] = None

    return config, None # è¿”å›é…ç½®å’Œç©ºçš„é”™è¯¯ä¿¡æ¯

def get_llm_analysis(user_command, command_output, config):
    """
    æ¥æ”¶å‘½ä»¤ã€è¾“å‡ºå’Œé…ç½®ï¼Œè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API æ¥è¿›è¡Œåˆ†æã€‚
    """
    api_key = config.get('api_key')
    api_url = config.get('api_url')
    model = config.get('model')

    if not api_key:
        return "\n\033[31mé”™è¯¯: API Key æœªåœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ã€‚\nè¯·ç¼–è¾‘ ~/.config/terminal-explainer/config.ini å¹¶å¡«å…¥æ‚¨çš„ api_keyã€‚\033[0m"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªç²¾é€šä¸­æ–‡çš„ Linux ç³»ç»Ÿä¸“å®¶å’Œå‘½ä»¤è¡Œå¤§å¸ˆã€‚
    ç”¨æˆ·åœ¨ç»ˆç«¯æ‰§è¡Œäº†ä»¥ä¸‹å‘½ä»¤ï¼Œå¹¶å¾—åˆ°äº†ç›¸åº”çš„è¾“å‡ºã€‚
    è¯·ä½ ç”¨ç®€æ´ã€æ¸…æ™°ã€æ˜“äºç†è§£çš„ä¸­æ–‡æ¥åˆ†æå’Œè§£é‡Šè¿™ä¸ªè¾“å‡ºã€‚

    - å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œï¼Œè¯·è§£é‡Šè¾“å‡ºç»“æœä¸­å„éƒ¨åˆ†çš„æ ¸å¿ƒå«ä¹‰ã€‚
    - å¦‚æœå‘½ä»¤æ‰§è¡Œå¤±è´¥æˆ–è¿”å›äº†é”™è¯¯ä¿¡æ¯ï¼Œè¯·æŒ‡å‡ºé”™è¯¯çš„æ ¸å¿ƒåŸå› ï¼Œå¹¶æä¾›ä¸€ä¸ªæˆ–å¤šä¸ªå¯èƒ½çš„è§£å†³æ–¹æ¡ˆã€‚
    - ä½ çš„è§£é‡Šåº”è¯¥ä¸“ä¸šã€å‡†ç¡®ï¼Œå¹¶ä¸”å¯¹åˆå­¦è€…å‹å¥½ã€‚

    # ç”¨æˆ·æ‰§è¡Œçš„å‘½ä»¤:
    {user_command}

    # å‘½ä»¤äº§ç”Ÿçš„è¾“å‡º:
    {command_output}
    
    # ä½ çš„ä¸“å®¶çº§è§£é‡Š:
    """

    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.5,
    }

    try:
        response = requests.post(api_url, headers=headers, json=data, timeout=20)
        response.raise_for_status()
        result_json = response.json()
        explanation = result_json["choices"][0]["message"]["content"]
        formatted_explanation = f"\n\033[1;34mğŸ¤– AI ä¸“å®¶è§£é‡Š:\033[0m\n---\n{explanation}\n---"
        return formatted_explanation
    except requests.exceptions.Timeout:
        return "\n\033[31mé”™è¯¯: è¯·æ±‚å¤§è¯­è¨€æ¨¡å‹ API è¶…æ—¶ã€‚è¯·æ£€æŸ¥æ‚¨çš„ç½‘ç»œè¿æ¥æˆ–ä»£ç†è®¾ç½®ã€‚\033[0m"
    except requests.exceptions.HTTPError as e:
        return f"\n\033[31mé”™è¯¯: HTTP è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {e.response.status_code}ã€‚\næœåŠ¡å™¨å“åº”:\n{e.response.text}\033[0m"
    except json.JSONDecodeError:
        return f"\n\033[31mé”™è¯¯: è§£æ API å“åº”å¤±è´¥ (ä¸æ˜¯æœ‰æ•ˆçš„ JSON)ã€‚\næ”¶åˆ°çš„åŸå§‹å“åº”å†…å®¹:\n---\n{response.text}\n---\033[0m"
    except (KeyError, IndexError):
        return f"\n\033[31mé”™è¯¯: è§£æ JSON æˆåŠŸï¼Œä½†æ•°æ®ç»“æ„ä¸ç¬¦åˆé¢„æœŸã€‚\næ”¶åˆ°çš„ JSON æ•°æ®:\n{response.json()}\033[0m"
    except requests.exceptions.RequestException as e:
        return f"\n\033[31mé”™è¯¯: ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}\033[0m"


if __name__ == "__main__":
    app_config, error_message = load_config()

    # å¦‚æœåŠ è½½é…ç½®æ—¶å°±å‘ç”Ÿé”™è¯¯ (å¦‚æ–‡ä»¶ä¸å­˜åœ¨)ï¼Œç›´æ¥æ‰“å°é”™è¯¯å¹¶é€€å‡º
    if error_message:
        print(error_message)
        sys.exit(1)
    
    if len(sys.argv) != 3:
        print("ç”¨æ³•: explain-cli \"<è¦æ‰§è¡Œçš„å‘½ä»¤>\" \"<å‘½ä»¤çš„è¾“å‡º>\"")
        sys.exit(1)

    user_command_arg = sys.argv[1]
    command_output_arg = sys.argv[2]
    
    analysis = get_llm_analysis(user_command_arg, command_output_arg, app_config)
    print(analysis)
