#!/usr/bin/env python3

import sys
import os
import requests
import json
import configparser  # 用于解析 .ini 配置文件
from pathlib import Path # 用于优雅地处理文件路径

def load_config():
    """
    加载配置信息。
    遵循的优先级顺序为: 环境变量 > 配置文件 > 代码中的默认值。
    这提供了最大的灵活性。
    
    返回:
        一个包含配置信息的字典 (dict)。
    """
    # 1. 设置默认配置
    config = {
        'api_key': None,
        'api_url': 'https://api.openai.com/v1/chat/completions',
        'model': 'gpt-3.5-turbo'
    }

    # 2. 从配置文件中读取配置，并覆盖默认值
    # 使用 Path.home() 来获取当前用户的主目录，构造配置文件的绝对路径
    config_path = Path.home() / '.config' / 'terminal-explainer' / 'config.ini'
    
    if config_path.exists():
        parser = configparser.ConfigParser()
        parser.read(config_path, encoding='utf-8') # 使用 utf-8 编码读取
        
        # 检查配置文件中是否存在 [API] 区块
        if 'API' in parser:
            api_config = parser['API']
            # 使用 .get() 方法，如果键不存在，则返回默认值，避免出错
            config['api_key'] = api_config.get('api_key', config['api_key'])
            config['api_url'] = api_config.get('api_url', config['api_url'])
            config['model'] = api_config.get('model', config['model'])
    
    # 3. 环境变量具有最高优先级，会覆盖之前所有的设置
    if 'OPENAI_API_KEY' in os.environ:
        config['api_key'] = os.environ['OPENAI_API_KEY']

    # 4. 清理可能存在的占位符
    # 防止用户忘记修改模板中的 'YOUR_API_KEY_HERE'
    if config['api_key'] == 'YOUR_API_KEY_HERE':
        config['api_key'] = None

    return config

def get_llm_analysis(user_command, command_output, config):
    """
    接收命令、输出和配置，调用大语言模型 API 来进行分析。
    
    参数:
        user_command (str): 用户在终端输入的命令。
        command_output (str): 执行命令后产生的输出。
        config (dict): 包含 API Key, URL 和 model 的配置字典。
        
    返回:
        经过格式化的、由 AI 生成的解释字符串 (str)。
    """
    # 从配置字典中安全地获取各项配置
    api_key = config.get('api_key')
    api_url = config.get('api_url')
    model = config.get('model')

    # 如果最终没有获取到 API Key，则返回错误信息
    if not api_key:
        return "\n\033[31m错误: API Key 未设置。\n请在环境变量 OPENAI_API_KEY 中提供，或在配置文件 ~/.config/terminal-explainer/config.ini 中设置。\033[0m"

    # 设置请求头，用于身份验证
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    # 这是发送给大语言模型的“提示”(Prompt)。它的质量直接决定了AI返回结果的质量。
    prompt = f"""
    你是一个精通中文的 Linux 系统专家和命令行大师。
    用户在终端执行了以下命令，并得到了相应的输出。
    请你用简洁、清晰、易于理解的中文来分析和解释这个输出。

    - 如果命令成功执行，请解释输出结果中各部分的核心含义。
    - 如果命令执行失败或返回了错误信息，请指出错误的核心原因，并提供一个或多个可能的解决方案。
    - 你的解释应该专业、准确，并且对初学者友好。

    # 用户执行的命令:
    {user_command}

    # 命令产生的输出:
    {command_output}
    
    # 你的专家级解释:
    """

    # 构造要发送的 JSON 数据
    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.5, # temperature 越低，输出越稳定；越高，越有创造性
    }

    try:
        # 发送 POST 请求到 API 服务器，并设置20秒超时
        response = requests.post(api_url, headers=headers, json=data, timeout=20)
        
        # 如果服务器返回了错误状态码 (如 401, 404, 500), 则主动抛出异常
        response.raise_for_status()
        
        # 尝试将服务器返回的响应文本解析为 JSON 对象
        result_json = response.json()
        
        # 从 JSON 对象中提取 AI 的回复内容
        explanation = result_json["choices"][0]["message"]["content"]
        
        # 对输出进行美化，使用 ANSI escape code 添加颜色和图标
        formatted_explanation = f"\n\033[1;34m🤖 AI 专家解释:\033[0m\n---\n{explanation}\n---"
        return formatted_explanation

    except requests.exceptions.Timeout:
        return "\n\033[31m错误: 请求大语言模型 API 超时。请检查您的网络连接或代理设置。\033[0m"
    
    except requests.exceptions.HTTPError as e:
        # 捕获 HTTP 错误，并将服务器返回的详细信息打印出来，方便排错
        return f"\n\033[31m错误: HTTP 请求失败，状态码: {e.response.status_code}。\n服务器响应:\n{e.response.text}\033[0m"
    
    except json.JSONDecodeError:
        # 如果服务器的响应不是一个有效的 JSON，则会触发此异常
        return f"\n\033[31m错误: 解析 API 响应失败 (不是有效的 JSON)。\n收到的原始响应内容:\n---\n{response.text}\n---\033[0m"
    
    except (KeyError, IndexError):
        # 如果 JSON 结构不符合预期 (例如缺少 "choices" 键)，则会触发此异常
        return f"\n\033[31m错误: 解析 JSON 成功，但数据结构不符合预期。\n收到的 JSON 数据:\n{response.json()}\033[0m"
    
    except requests.exceptions.RequestException as e:
        # 捕获其他所有与请求相关的异常，如 DNS 解析失败、连接被拒绝等
        return f"\n\033[31m错误: 网络请求失败: {e}\033[0m"


# 当这个脚本作为主程序直接运行时，以下代码块将被执行
if __name__ == "__main__":
    # 首先，加载所有配置
    app_config = load_config()

    # 检查从命令行传入的参数数量是否正确
    # sys.argv 是一个列表，包含了所有命令行参数
    # sys.argv[0] 是脚本名, sys.argv[1] 是第一个参数, 以此类推
    if len(sys.argv) != 3:
        print("用法: explain-cli \"<要执行的命令>\" \"<命令的输出>\"")
        sys.exit(1) # 异常退出

    # 从命令行参数中获取命令和输出
    user_command_arg = sys.argv[1]
    command_output_arg = sys.argv[2]
    
    # 调用核心分析函数，并传入配置
    analysis = get_llm_analysis(user_command_arg, command_output_arg, app_config)
    
    # 将最终结果打印到标准输出
    print(analysis)
