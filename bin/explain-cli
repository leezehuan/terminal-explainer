#!/usr/bin/env python3

import sys
import os
import requests
import json
import configparser
from pathlib import Path

def load_config():
    """
    åŠ è½½é…ç½®ä¿¡æ¯ã€‚
    """
    print("[è°ƒè¯•ä¿¡æ¯] æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶...")
    config = {
        'api_key': None,
        'api_url': 'https://api.openai.com/v1/chat/completions',
        'model': 'gpt-3.5-turbo'
    }

    config_path = Path.home() / '.config' / 'terminal-explainer' / 'config.ini'
    
    if not config_path.exists():
        return None, f"\n\033[31mé”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼\n[è°ƒè¯•ä¿¡æ¯] è„šæœ¬åœ¨è·¯å¾„ '{config_path}' æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ã€‚\033[0m"

    print(f"[è°ƒè¯•ä¿¡æ¯] æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_path}")
    parser = configparser.ConfigParser()
    parser.read(config_path, encoding='utf-8')
    
    if 'API' in parser:
        api_config = parser['API']
        print("[è°ƒè¯•ä¿¡æ¯] æˆåŠŸè¯»å– [API]åŒºå—ã€‚")
        config['api_key'] = api_config.get('api_key')
        config['api_url'] = api_config.get('api_url')
        config['model'] = api_config.get('model')
        
        # æ‰“å°è¯»å–åˆ°çš„å€¼ï¼Œéšè—api_keyæ•æ„Ÿéƒ¨åˆ†
        safe_key = config.get('api_key')
        if safe_key and len(safe_key) > 8:
            safe_key = f"{safe_key[:4]}...{safe_key[-4:]}"
        print(f"[è°ƒè¯•ä¿¡æ¯] è¯»å–åˆ°çš„é…ç½®: api_key={safe_key}, api_url={config.get('api_url')}, model={config.get('model')}")

    else:
        print("[è°ƒè¯•ä¿¡æ¯] è­¦å‘Š: é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° [API] åŒºå—ã€‚")

    if config['api_key'] == 'YOUR_API_KEY_HERE':
        print("[è°ƒè¯•ä¿¡æ¯] æ£€æµ‹åˆ° api_key ä»æ˜¯å ä½ç¬¦ 'YOUR_API_KEY_HERE'ï¼Œå°†å…¶è§†ä¸ºç©ºå€¼ã€‚")
        config['api_key'] = None

    return config, None

def get_llm_analysis(user_command, command_output, config):
    """
    è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ APIã€‚
    """
    print("[è°ƒè¯•ä¿¡æ¯] è¿›å…¥ get_llm_analysis å‡½æ•°ã€‚")
    api_key = config.get('api_key')
    
    if not api_key:
        return "\n\033[31mé”™è¯¯: API Key æœªè®¾ç½®ã€‚\n[è°ƒè¯•ä¿¡æ¯] åŸå› : ä»é…ç½®æ–‡ä»¶åŠ è½½åï¼Œapi_key çš„å€¼ä¸ºç©ºã€‚è¯·æ£€æŸ¥æ‚¨çš„é…ç½®æ–‡ä»¶ã€‚\033[0m"
    
    print("[è°ƒè¯•ä¿¡æ¯] API Key å­˜åœ¨ï¼Œå‡†å¤‡å‘é€ç½‘ç»œè¯·æ±‚...")
    # ... çœç•¥äº† prompt å’Œ headers çš„æ„é€ ï¼Œå®ƒä»¬ä¸å¤ªå¯èƒ½å‡ºé”™ ...
    api_url = config.get('api_url')
    model = config.get('model')
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    prompt = f"å‘½ä»¤: {user_command}\nè¾“å‡º: {command_output}\nè¯·è§£é‡Šã€‚" # ç®€åŒ– prompt ç”¨äºè°ƒè¯•
    data = {"model": model, "messages": [{"role": "user", "content": prompt}], "temperature": 0.5}

    try:
        response = requests.post(api_url, headers=headers, json=data, timeout=20)
        print(f"[è°ƒè¯•ä¿¡æ¯] æ”¶åˆ°æœåŠ¡å™¨å“åº”ï¼ŒçŠ¶æ€ç : {response.status_code}")
        response.raise_for_status()
        result_json = response.json()
        explanation = result_json["choices"][0]["message"]["content"]
        formatted_explanation = f"\n\033[1;34mğŸ¤– AI ä¸“å®¶è§£é‡Š:\033[0m\n---\n{explanation}\n---"
        return formatted_explanation
    except Exception as e:
        # æ•è·æ‰€æœ‰å¼‚å¸¸å¹¶æ‰“å°è¯¦ç»†ä¿¡æ¯
        return f"\n\033[31mé”™è¯¯: åœ¨ç½‘ç»œè¯·æ±‚æˆ–è§£æè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸ã€‚\n[è°ƒè¯•ä¿¡æ¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}\n[è°ƒè¯•ä¿¡æ¯] å¼‚å¸¸è¯¦æƒ…: {e}\033[0m"


if __name__ == "__main__":
    # --- è„šæœ¬å…¥å£ ---
    print("\n--- [è°ƒè¯•æ¨¡å¼] ---")
    print("explain-cli è„šæœ¬å·²å¯åŠ¨ã€‚")
    
    app_config, error_message = load_config()

    if error_message:
        print(error_message)
        sys.exit(1)
    
    if len(sys.argv) != 3:
        print(f"ç”¨æ³•: explain-cli \"<å‘½ä»¤>\" \"<è¾“å‡º>\"\n[è°ƒè¯•ä¿¡æ¯] æ”¶åˆ°çš„å‚æ•°æ•°é‡: {len(sys.argv)}, å†…å®¹: {sys.argv}")
        sys.exit(1)

    print("[è°ƒè¯•ä¿¡æ¯] å‚æ•°æ•°é‡æ­£ç¡®ï¼Œå‡†å¤‡è°ƒç”¨åˆ†æå‡½æ•°...")
    user_command_arg = sys.argv[1]
    command_output_arg = sys.argv[2]
    
    analysis = get_llm_analysis(user_command_arg, command_output_arg, app_config)
    
    print("\n--- [æœ€ç»ˆè¾“å‡º] ---")
    print(analysis)
    print("--- [è°ƒè¯•ç»“æŸ] ---")

